install.packages("rpart")
install.packages("rpart.plot")
devtools::install_github("devanshagr/CrossValidation")
# Now lets import the rpart.plot library to use the rpart.plot() function.
library(rpart.plot)
devtools::install_github("devanshagr/CrossValidation")
#Freestyle (16.4.1)
train<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/HireTrainApr10.csv')
test<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/HireTestFull.csv')
colnames(train)
decision<-rep('No',nrow(train))
decision[train$College!='BestCollege'& train$Coding!='Weak']<-'Yes'
decision[train$Major!='IT' & train$Impression!='Outgoing' &train$Coding=='Excellent']<-'Yes'
accuracy<-round(mean(train$Hired==decision),2)
print(paste("The accuracy of professor model on traing data is",accuracy))
decision<-rep('No',nrow(test))
decision[test$College!='BestCollege'& test$Coding!='Weak']<-'Yes'
decision[test$Major!='IT' & test$Impression!='Outgoing' &test$Coding=='Excellent']<-'Yes'
accuracy<-round(mean(test$Hired==decision),2)
print(paste("The accuracy of professor model on test data is",accuracy))
#Freestyle (16.4.2)
decision = rep('Yes', nrow(train))
decision[train$Impression == "Nerdy" & train$Major == "IT" & train$College == "BestCollege"] <- "No"
decision[train$Coding == "OK" & train$Impression == "Shy" & train$College == "BestCollege"] <-"No"
decision[train$Coding == "OK" & train$Impression == "Nerdy" & train$College == "BestCollege"] <- "No"
decision[train$Coding == 'Weak']<-'No'
decision[train$Coding == "Weak" & train$Impression == "Nerdy" & train$College =="Redbrick"] <- "Yes"
accuracy<-round(mean(train$Hired==decision),2)
print(paste("The accuracy of student model on training data is",accuracy))
decision = rep('Yes', nrow(test))
decision[test$Impression == "Nerdy" & test$Major == "IT" & test$College == "BestCollege"] <- "No"
decision[test$Coding == "OK" & test$Impression == "Shy" & test$College == "BestCollege"] <-"No"
decision[test$Coding == "OK" & test$Impression == "Nerdy" & test$College == "BestCollege"] <- "No"
decision[test$Coding == 'Weak']<-'No'
decision[test$Coding == "Weak" & test$Impression == "Nerdy" & test$College =="Redbrick"] <- "Yes"
accuracy<-round(mean(test$Hired==decision),2)
print(paste("The accuracy of student model on test data is",accuracy))
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class")
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
CrossValidation::cross_validate(train, tree, 10, 0.8)
# R-part (min-split 200)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minsplit = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (min-split 100)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minsplit = 100))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (min-bucket 100)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minbucket = 100))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (min-bucket 200)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minbucket = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (cp - 0.05)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(cp = 0.05))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (cp - 0.005)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(cp = 0.005))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
rm(list = ls())
train<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
head(train)
summary(train)
# scramble the train frame
v<-sample(1:nrow(train))
v
v[1:5]
trainScrambled<-train[v, ]
trainScrambled
head(trainScrambled)
# one step crossvalidation
trainSample<-trainScrambled[nrow(trainScrambled)-200:nrow(trainScrambled), ]
summary(trainSample)
head(trainSample)
head(train)
myprediction<-trainSample
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80 ] <- 'A'
myprediction$Grade <-decision
error <- mean(trainSample$Grade!= myprediction$Grade)
error
test<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022testSNoGrade.csv')
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022submission.csv')
myprediction<-test
# Here is your model. I just show example of trivial prediction model
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
submission$Grade<-decision
submission
rm(list = ls())
#Freestyle (16.4.1)
train<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/HireTrainApr10.csv')
test<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/HireTestFull.csv')
colnames(train)
decision<-rep('No',nrow(train))
decision[train$College!='BestCollege'& train$Coding!='Weak']<-'Yes'
decision[train$Major!='IT' & train$Impression!='Outgoing' &train$Coding=='Excellent']<-'Yes'
accuracy<-round(mean(train$Hired==decision),2)
print(paste("The accuracy of professor model on traing data is",accuracy))
decision<-rep('No',nrow(test))
decision[test$College!='BestCollege'& test$Coding!='Weak']<-'Yes'
decision[test$Major!='IT' & test$Impression!='Outgoing' &test$Coding=='Excellent']<-'Yes'
accuracy<-round(mean(test$Hired==decision),2)
print(paste("The accuracy of professor model on test data is",accuracy))
#Freestyle (16.4.2)
decision = rep('Yes', nrow(train))
decision[train$Impression == "Nerdy" & train$Major == "IT" & train$College == "BestCollege"] <- "No"
decision[train$Coding == "OK" & train$Impression == "Shy" & train$College == "BestCollege"] <-"No"
decision[train$Coding == "OK" & train$Impression == "Nerdy" & train$College == "BestCollege"] <- "No"
decision[train$Coding == 'Weak']<-'No'
decision[train$Coding == "Weak" & train$Impression == "Nerdy" & train$College =="Redbrick"] <- "Yes"
accuracy<-round(mean(train$Hired==decision),2)
print(paste("The accuracy of student model on training data is",accuracy))
decision = rep('Yes', nrow(test))
decision[test$Impression == "Nerdy" & test$Major == "IT" & test$College == "BestCollege"] <- "No"
decision[test$Coding == "OK" & test$Impression == "Shy" & test$College == "BestCollege"] <-"No"
decision[test$Coding == "OK" & test$Impression == "Nerdy" & test$College == "BestCollege"] <- "No"
decision[test$Coding == 'Weak']<-'No'
decision[test$Coding == "Weak" & test$Impression == "Nerdy" & test$College =="Redbrick"] <- "Yes"
accuracy<-round(mean(test$Hired==decision),2)
print(paste("The accuracy of student model on test data is",accuracy))
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class")
rpart.plot(tree)
tree <- rpart(Hired ~ Impression+Major+Coding+College, data = train,method = "class")
tree <- rpart(Hired ~ Impression+Major+Coding+College, data = train,method = "class")
rpart.plot(tree)
tree <- rpart(Hired ~ Impression+Major+Coding, data = train,method = "class")
rpart.plot(tree)
tree <- rpart(Hired ~ Impression+Major+Coding+College, data = train,method = "class")
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
pred
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
CrossValidation::cross_validate(train, tree, 10, 0.8)
# R-part (min-split 200)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minsplit = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (min-split 100)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minsplit = 100))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (min-bucket 100)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minbucket = 100))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (min-bucket 200)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minbucket = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (cp - 0.05)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(cp = 0.05))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
# R-part (cp - 0.005)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(cp = 0.005))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022submission.csv')
myprediction<-test
# Here is your model. I just show example of trivial prediction model
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
submission$Grade<-decision
submission
test<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022testSNoGrade.csv')
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022submission.csv')
myprediction<-test
# Here is your model. I just show example of trivial prediction model
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
submission$Grade<-decision
submission
#Freestyle (16.4.1)
train<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/HireTrainApr10.csv')
test<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/HireTestFull.csv')
colnames(train)
decision<-rep('No',nrow(train))
decision[train$College!='BestCollege'& train$Coding!='Weak']<-'Yes'
decision[train$Major!='IT' & train$Impression!='Outgoing' &train$Coding=='Excellent']<-'Yes'
accuracy<-round(mean(train$Hired==decision),2)
print(paste("The accuracy of professor model on traing data is",accuracy))
decision<-rep('No',nrow(test))
decision[test$College!='BestCollege'& test$Coding!='Weak']<-'Yes'
decision[test$Major!='IT' & test$Impression!='Outgoing' &test$Coding=='Excellent']<-'Yes'
accuracy<-round(mean(test$Hired==decision),2)
print(paste("The accuracy of professor model on test data is",accuracy))
#Freestyle (16.4.2)
decision = rep('Yes', nrow(train))
decision[train$Impression == "Nerdy" & train$Major == "IT" & train$College == "BestCollege"] <- "No"
decision[train$Coding == "OK" & train$Impression == "Shy" & train$College == "BestCollege"] <-"No"
decision[train$Coding == "OK" & train$Impression == "Nerdy" & train$College == "BestCollege"] <- "No"
decision[train$Coding == 'Weak']<-'No'
decision[train$Coding == "Weak" & train$Impression == "Nerdy" & train$College =="Redbrick"] <- "Yes"
accuracy<-round(mean(train$Hired==decision),2)
print(paste("The accuracy of student model on training data is",accuracy))
decision = rep('Yes', nrow(test))
decision[test$Impression == "Nerdy" & test$Major == "IT" & test$College == "BestCollege"] <- "No"
decision[test$Coding == "OK" & test$Impression == "Shy" & test$College == "BestCollege"] <-"No"
decision[test$Coding == "OK" & test$Impression == "Nerdy" & test$College == "BestCollege"] <- "No"
decision[test$Coding == 'Weak']<-'No'
decision[test$Coding == "Weak" & test$Impression == "Nerdy" & test$College =="Redbrick"] <- "Yes"
accuracy<-round(mean(test$Hired==decision),2)
print(paste("The accuracy of student model on test data is",accuracy))
tree <- rpart(Hired ~ Impression+Major+Coding+College, data = train,method = "class")
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
CrossValidation::cross_validate(train, tree, 10, 0.8)
# R-part (min-split 200)
tree <- rpart(Hired ~ Impression+Major+College+Coding, data = train,method = "class", control=rpart.control(minsplit = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Hired==pred)
pred <- predict(tree, test, type="class")
head(pred)
mean(test$Hired==pred)
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/HireSubmission.csv')
submission<-read.csv('https://raw.githubusercontent.com/paramshah4/data101_tutorial/main/files/dataset/submissionMovies2023.csv')
train<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
train
train<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
test<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022testSNoGrade.csv')
train
##freestyle:
myprediction<-train
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80 ] <- 'A'
myprediction$Grade <-decision
error <- mean(trainSample$Grade!= myprediction$Grade)
error
myprediction<-test
error <- mean(train$Grade!= myprediction$Grade)
train<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
test<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022testSNoGrade.csv')
train
##freestyle:
myprediction<-train
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80 ] <- 'A'
myprediction$Grade <-decision
error <- mean(train$Grade!= myprediction$Grade)
error
myprediction<-test
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
##rpart:
tree <- rpart(Grade ~ GPA+Major+Score+Seniority, data = train,method = "class", control=rpart.control(minsplit = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Grade==pred)
CrossValidation::cross_validate(train, tree, 10, 0.8)
pred <- predict(tree, test, type="class")
test
##rpart:
tree <- rpart(Grade ~ Major+Score+Seniority, data = train,method = "class", control=rpart.control(minsplit = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Grade==pred)
CrossValidation::cross_validate(train, tree, 10, 0.8)
pred <- predict(tree, test, type="class")
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022submission.csv')
submission$Grade<-decision
submission$Grade<-pred
submission
library(rpart)
library(rpart.plot)
train<-read.csv("https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/MoodyMarch2022b.csv")
test<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022testSNoGrade.csv')
test
##freestyle:
myprediction<-train
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80 ] <- 'A'
myprediction$Grade <-decision
error <- mean(train$Grade!= myprediction$Grade)
error
myprediction<-test
decision <- rep('F',nrow(myprediction))
decision[myprediction$Score>40] <- 'D'
decision[myprediction$Score>60] <- 'C'
decision[myprediction$Score>70] <- 'B'
decision[myprediction$Score>80] <- 'A'
##rpart:
tree <- rpart(Grade ~ Major+Score+Seniority, data = train,method = "class", control=rpart.control(minsplit = 200))
rpart.plot(tree)
pred <- predict(tree, train, type="class")
head(pred)
mean(train$Grade==pred)
CrossValidation::cross_validate(train, tree, 10, 0.8)
pred <- predict(tree, test, type="class")
submission<-read.csv('https://raw.githubusercontent.com/dev7796/data101_tutorial/main/files/dataset/M2022submission.csv')
submission$Grade<-pred
submission
write.csv(submission, 'submission.csv', row.names=FALSE) # to store submission as csv file on your machine and subsequently submit it on Kaggle
# dont forget to set rows.names as FALSE
